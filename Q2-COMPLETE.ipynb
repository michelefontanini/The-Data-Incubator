{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 432878 entries, 0 to 432877\n",
      "Data columns (total 8 columns):\n",
      "disposition       432878 non-null object\n",
      "location          432878 non-null object\n",
      "policedistrict    432878 non-null int64\n",
      "priority          432877 non-null object\n",
      "timearrive        338935 non-null object\n",
      "timecreate        432878 non-null object\n",
      "timedispatch      292661 non-null object\n",
      "type_             432878 non-null object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 29.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "group_size = 50000 #max block size\n",
    "\n",
    "query = (\"https://data.nola.gov/resource/w68y-xmk6.json?\"\n",
    "         \"$select=type_,timedispatch,timearrive,disposition,timecreate,location,policedistrict,priority\"\n",
    "         #columns of interest \n",
    "         \"&$limit=\" + str(group_size) +\n",
    "         \"&$order=nopd_item\"\n",
    "         \"&$offset=\")\n",
    "\n",
    "group_id = 0\n",
    "df_list = []\n",
    "condition = True\n",
    "while condition:\n",
    "    the_offset = group_id * group_size\n",
    "    df_list.append(pd.read_json(query + str(the_offset))) #loading data frame in chuncks\n",
    "    group_id += 1\n",
    "    condition = not df_list[-1].empty #until full database is taken\n",
    "\n",
    "df2015 = pd.concat(df_list, ignore_index=True) # building the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1:\n",
    "    What fraction of calls are of the most common type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of most common calls = 0.246351166\n"
     ]
    }
   ],
   "source": [
    "print 'fraction of most common calls =', format(float(df2015['type_'].value_counts().max())/len(df2015),'.9f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2:\n",
    "Some calls result in an officer being dispatched to the scene, and some log an arrival time. What is the median response time (dispatch to arrival), in seconds, considering only valid (i.e. non-negative) times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           timearrive        timedispatch\n",
      "0 2015-01-01 01:41:20 2015-01-01 01:24:47\n",
      "3 2015-01-01 00:13:19 2015-01-01 00:08:17\n",
      "7 2015-01-01 00:13:46 2015-01-01 00:06:15\n",
      "8 2015-01-01 00:09:18 2015-01-01 00:07:12\n"
     ]
    }
   ],
   "source": [
    "times_df = df2015.dropna()[['timearrive', 'timedispatch']].applymap(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S'))\n",
    "# transforming strings into datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeDif(row): # calculating the difference row by row\n",
    "    return (row['timearrive'] - row['timedispatch']).total_seconds()\n",
    "deltas = times_df.apply(timeDif, axis=1)\n",
    "deltas = deltas[deltas > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average response time = 496.1900981\n"
     ]
    }
   ],
   "source": [
    "mean_response_time = deltas.mean(axis=0)\n",
    "print 'average response time =', format(mean_response_time, '.7f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Work out the average (mean) response time in each district. What is the difference between the average response times of the districts with the longest and shortest times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference in average response time = 445.3391748\n"
     ]
    }
   ],
   "source": [
    "deltas = pd.concat([deltas, df2015.ix[deltas.index,'policedistrict']], axis=1) #merging Dt and districts\n",
    "deltas.columns = ['deltaT', 'policedistrict']\n",
    "avgtimes = deltas.groupby(['policedistrict']).mean()\n",
    "maxdelta = max(avgtimes['deltaT']) - min(avgtimes['deltaT'])\n",
    "print 'difference in average response time =', format(maxdelta, '.7f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4:\n",
    "We can define surprising event types as those that occur more often in a district than they do over the whole city. What is the largest ratio of the conditional probability of an event type given a district to the unconditional probably of that event type? Consider only events types which have more than 100 events. Note that some events have their locations anonymized and are reported as being in district \"0\". These should be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surprising_df = df2015.ix[df2015['policedistrict'] != 0,['type_','policedistrict']] #looking at types in distr. 1 to 8\n",
    "tot_crimes = surprising_df['type_'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_counts = surprising_df['type_'].value_counts()\n",
    "freq_types = t_counts[t_counts > 100].index # selecting types with 100+ entries\n",
    "p_counts =  surprising_df['policedistrict'].value_counts()\n",
    "p_probs = p_counts / tot_crimes #calculating probability of districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_list = []\n",
    "for type_select in freq_types:        #preparing for prob frame\n",
    "    for dist_select in p_counts.index:\n",
    "        event_prob = float(t_counts[type_select]) / tot_crimes #event probability\n",
    "        p_prob = float(p_counts[dist_select]) / tot_crimes # local prob\n",
    "        intersect_prob = float(surprising_df.ix[(surprising_df['policedistrict'] == dist_select) & (surprising_df['type_'] == type_select), 'type_'].count()) / tot_crimes\n",
    "        cond_prob = intersect_prob / p_prob\n",
    "        prob_list.append([event_prob,p_prob,intersect_prob,cond_prob])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prob ratio of conditional/total prob = 6.4630492074\n"
     ]
    }
   ],
   "source": [
    "probframe = pd.DataFrame(prob_list) #building frame\n",
    "probframe.columns = ['ev_prob','dist_prob','inters_prob','cond_prob']\n",
    "probframe['prob_ratio'] = probframe['cond_prob'] / probframe['ev_prob']\n",
    "print 'max prob ratio of conditional/total prob =', probframe['prob_ratio'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5:\n",
    "Find the call type that displayed the largest percentage decrease in volume between 2011 and 2015. What is the fraction of the 2011 volume that this decrease represents? The answer should be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also for 2011 data we need do get df in chunks\n",
    "query11 = (\"https://data.nola.gov/resource/j7t8-jceh.json?\"\n",
    "           \"$select=type\"\n",
    "           #columns of interest \n",
    "           \"&$limit=\" + str(group_size) +\n",
    "           \"&$order=nopd_item\"\n",
    "           \"&$offset=\")\n",
    "\n",
    "group_id = 0\n",
    "df_list = []\n",
    "condition = True\n",
    "while condition:\n",
    "    the_offset = group_id * group_size\n",
    "    df_list.append(pd.read_json(query11 + str(the_offset))) #loading data frame in chuncks\n",
    "    group_id += 1\n",
    "    condition = not df_list[-1].empty #until full database is taken\n",
    "\n",
    "df2011 = pd.concat(df_list, ignore_index=True) # building the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max decreased type = 89 ratio w.r.t. 2011 =  0.994444444\n"
     ]
    }
   ],
   "source": [
    "type11 = df2011.groupby(['type'])['type'].count()\n",
    "type15 = df2015.groupby(['type_'])['type_'].count()\n",
    "max_decr_type = ((type11 - type15 )/ type11).argmax()\n",
    "ratio_decr = ((type11 - type15 )/ type11).max()\n",
    "print 'max decreased type =', max_decr_type, 'ratio w.r.t. 2011 = ', format(ratio_decr, '.9f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6:\n",
    "The disposition represents the action that was taken to address the serivce call. Consider how the disposition of calls changes with the hour of the record's creation time. Find the disposition whose fraction of that hour's disposition varies the most over a typical day. What is its change (maximum fraction minus minimum fraction)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the disposition that varies the max during the day has a variation of = 0.218860217348\n"
     ]
    }
   ],
   "source": [
    "disp_df = pd.concat([df2015['disposition'], df2015['timecreate'].apply(lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S').hour)], axis=1)\n",
    "disp_group = disp_df.groupby(['timecreate','disposition'])\n",
    "disp_count = disp_group.disposition.count()\n",
    "sumdisp = disp_count.sum(level='timecreate')\n",
    "frac_disp = disp_count / sumdisp \n",
    "sw_sorted = frac_disp.swaplevel('timecreate','disposition').sortlevel(0)\n",
    "print 'the disposition that varies the max during the day has a variation of =', (sw_sorted.max(level=0) - sw_sorted.min(level=0)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7:\n",
    "We can use the call locations to estimate the areas of the police districts. Represent each as an ellipse with semi-axes given by a single standard deviation of the longitude and latitude. What is the area, in square kilometers, of the largest district measured in this manner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def val_select(row):\n",
    "    if (not row.values()[1]) & (29.8 < float(row.values()[0]) < 30.21) & (-90.2 < float(row.values()[2]) < -89.5): \n",
    "        # a quick check at the map shows New Orleans is contained in 29.8-30.21 -90.2 - -89.5, eliminating bad entries\n",
    "        row_mask.append(True)\n",
    "    else: \n",
    "        row_mask.append(False)\n",
    "    return #row.values()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the area in km^2 of the largest police district is 24.9361986917  corresponding to district 7\n"
     ]
    }
   ],
   "source": [
    "row_mask = []\n",
    "df2015.ix[:,'location'].apply(lambda x: val_select(x)) # getting the interesting rows\n",
    "grouped = df2015.ix[row_mask,['location','policedistrict']].groupby('policedistrict')\n",
    "\n",
    "def axis_to_area (axis_a, axis_b, center_a):\n",
    "    Ravg = 6371 #in km\n",
    "    latr = center_a * np.pi / 180\n",
    "    D_latr = axis_a * np.pi / 180\n",
    "    D_longr = axis_b * np.pi / 180\n",
    "    # using Haversine formula for the great circle distance between 2 points\n",
    "    # d_const_lat = 2R arcsin(cos(latr) abs(sin(D_longr/2))\n",
    "    # d_const_long = R abs(D_latr)\n",
    "    # R = 6371km (avg) Xr = pi/180 Xdeg \n",
    "    d_const_lat = 2 * Ravg * np.arcsin(np.cos(latr) * np.abs( np.sin(D_longr / 2) ) )\n",
    "    d_const_long = Ravg * np.abs(D_latr)                   \n",
    "    return np.pi * d_const_lat * d_const_long\n",
    "\n",
    "def area_func (df, column='location'):\n",
    "    axis_a = df[column].apply( lambda x: float(x.values()[0]) ).std()\n",
    "    center_a = df[column].apply( lambda x: float(x.values()[0]) ).mean()\n",
    "    axis_b = df[column].apply( lambda x: float(x.values()[2]) ).std()\n",
    "    return axis_to_area(axis_a, axis_b, center_a)\n",
    "\n",
    "areas = grouped.apply(area_func)\n",
    "print 'the area in km^2 of the largest police district is', areas.max(), ' corresponding to district', areas.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8:\n",
    "The calls are assigned a priority. Some types of calls will receive a greater variety of priorities. To understand which type of call has the most variation in priority, find the type of call whose most common priority is the smallest fraction of all calls of that type. What is that smallest fraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the smallest fraction of calls of the most variate type = 0.475138121547\n"
     ]
    }
   ],
   "source": [
    "temp = df2015.groupby(['type_','priority']).priority.count()\n",
    "sumtmp = temp.sum(level='type_')\n",
    "min_fraction = (temp.max(level='type_') / sumtmp).min()\n",
    "print 'the smallest fraction of calls of the most variate type =', min_fraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
